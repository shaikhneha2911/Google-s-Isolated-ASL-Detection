# Google-s-Isolated-ASL-Detection
- The ability to communicate through sign language is essential for many people who are
deaf or hard of hearing, but current Isolated Sign Language Recognition (ISLR) technologies
often require specialized equipment or sensors, limiting their usefulness and accessibility.
- In this project, we aim to develop a new ISLR system that uses only a standard RGB camera for
American sign language detection, tracking, and sign recognition. Our system leverages
cutting-edge computer vision techniques and deep learning models to accurately identify signs in
real-time, and we will evaluate its performance on publicly available datasets and through user
studies with deaf signers. Our proposed ISLR system has the potential to improve
communication and reduce barriers for those who rely on sign language.
- Specifically for this project, we choose to join an active Kaggle competition: Google -
Isolated Sign Language Recognition. The goal of this competition is to build an American sign
language recognizer for an app named PopSign which is designed for people who are willing to
learn sign language to effectively communicate with others who may lose the ability to hear. In
addition, the PopSign smart app is open to the public for people to watch and learn American
sign language for interest.
- Since it was a sequential problem I selected LSTM and Transformers model.
- By working on this project I gained experience working with Landmark Data and Parque files.
  
